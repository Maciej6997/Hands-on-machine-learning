{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: Try a Support Vector Machine regressor (sklearn.svm.SVR) with various hyperparameters, such as kernel=\"linear\" (with various values for the C hyperparameter) or kernel=\"rbf\" (with various values for the C and gamma hyperparameters). Note that SVMs don't scale well to large datasets, so you should probably train your model on just the first 5,000 instances of the training set and use only 3-fold cross-validation, or else it will take hours. Don't worry about what the hyperparameters mean for now (see the SVM notebook if you're interested). How does the best SVR predictor perform?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m housing \u001b[38;5;241m=\u001b[39m load_housing_data()\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompose\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m make_column_selector, make_column_transformer, ColumnTransformer\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mClasses\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardScalerClone, ClusterSimilarity\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Pipeline, make_pipeline\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FunctionTransformer, StandardScaler, OneHotEncoder\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'Classes'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('.'))  # Dodanie bieżącego katalogu\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from Functions import load_housing_data, shuffle_and_split, split_data_with_id_hash\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "housing = load_housing_data()\n",
    "from sklearn.compose import make_column_selector, make_column_transformer, ColumnTransformer\n",
    "from Classes import StandardScalerClone, ClusterSimilarity\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ścieżka Pythona:\n",
      "['C:\\\\Users\\\\macie\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\python313.zip', 'C:\\\\Users\\\\macie\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\DLLs', 'C:\\\\Users\\\\macie\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib', 'C:\\\\Users\\\\macie\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313', 'c:\\\\Users\\\\macie\\\\OneDrive\\\\Desktop\\\\Nauka2\\\\.venv', '', 'c:\\\\Users\\\\macie\\\\OneDrive\\\\Desktop\\\\Nauka2\\\\.venv\\\\Lib\\\\site-packages', 'c:\\\\Users\\\\macie\\\\OneDrive\\\\Desktop\\\\Nauka2\\\\.venv\\\\Lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\macie\\\\OneDrive\\\\Desktop\\\\Nauka2\\\\.venv\\\\Lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\macie\\\\OneDrive\\\\Desktop\\\\Nauka2\\\\.venv\\\\Lib\\\\site-packages\\\\Pythonwin', 'c:\\\\Users\\\\macie\\\\OneDrive', 'c:\\\\Users\\\\macie']\n",
      "\n",
      "Pliki w bieżącym katalogu:\n",
      "['.849C9593-D756-4E56-8D6E-42412F2A707B', 'datasets', 'Desktop', 'desktop.ini', 'Documents', 'Magazyn osobisty.lnk', 'Pictures', 'Załączniki e-mail']\n",
      "\n",
      "Pliki w katalogu wyżej:\n",
      "['.gitconfig', '.gk', '.ipython', '.matplotlib', '.vscode', 'AppData', 'Contacts', 'Cookies', 'Dane aplikacji', 'Documents', 'Downloads', 'Favorites', 'IntelGraphicsProfiles', 'Links', 'Menu Start', 'Moje dokumenty', 'Music', 'NetHood', 'NTUSER.DAT', 'ntuser.dat.LOG1', 'ntuser.dat.LOG2', 'NTUSER.DAT{7d7a8652-b521-11ef-8934-9021dc4fa3d0}.TM.blf', 'NTUSER.DAT{7d7a8652-b521-11ef-8934-9021dc4fa3d0}.TMContainer00000000000000000001.regtrans-ms', 'NTUSER.DAT{7d7a8652-b521-11ef-8934-9021dc4fa3d0}.TMContainer00000000000000000002.regtrans-ms', 'ntuser.ini', 'OneDrive', 'PrintHood', 'Recent', 'Saved Games', 'Searches', 'SendTo', 'Szablony', 'Ustawienia lokalne', 'Videos']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "print(\"Ścieżka Pythona:\")\n",
    "print(sys.path)\n",
    "\n",
    "print(\"\\nPliki w bieżącym katalogu:\")\n",
    "print(os.listdir('.'))\n",
    "\n",
    "print(\"\\nPliki w katalogu wyżej:\")\n",
    "print(os.listdir('..'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA DOWNLOAD AND SPLIT\n",
    "Use transformation from chapter_2_notebook, in this exercies i only want to check how SVM perfrom, without going into details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = load_housing_data()\n",
    "housing['income_cat'] = pd.cut(housing['median_income'], \n",
    "                               bins = [0., 1.5, 3.0, 4.5, 6., np.inf ], \n",
    "                               labels = [1, 2, 3, 4, 5])\n",
    "\n",
    "strat_train_set, strat_test_set = train_test_split(housing, test_size = 0.2, stratify = housing['income_cat'], random_state = 42)\n",
    "\n",
    "for set_ in (strat_test_set, strat_train_set):\n",
    "    set_.drop('income_cat', axis = 1, inplace = True)\n",
    "\n",
    "housing = strat_test_set.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_ratio(X):\n",
    "    return X[ :, [0]] / X[ :, [1]]\n",
    "\n",
    "def ratio_name(function_transformer, feature_names_in):\n",
    "    return ['ratio']\n",
    "\n",
    "def ratio_pipeline():\n",
    "    return make_pipeline(\n",
    "        SimpleImputer(strategy = 'median'),\n",
    "        FunctionTransformer(column_ratio, feature_names_out = ratio_name),\n",
    "        StandardScaler()\n",
    "    )\n",
    "\n",
    "log_pipeline = make_pipeline(\n",
    "    SimpleImputer(strategy = 'median'),\n",
    "    FunctionTransformer(np.log, feature_names_out = 'one-to-one'),\n",
    "    StandardScaler()\n",
    ")\n",
    "\n",
    "cluster_simil = ClusterSimilarity(n_clusters = 10, gamma = 1, random_state = 42)\n",
    "default_num_pipeline = make_pipeline(SimpleImputer(strategy = 'median'))\n",
    "preprocessing = ColumnTransformer([\n",
    "    ('bedroom_ratio', ratio_pipeline(), ['total_bedrooms', 'total_rooms']), \n",
    "    ('rooms_per_family', ratio_pipeline(), ['total_rooms', 'households']), \n",
    "    ('people_per_house', ratio_pipeline(), ['population', 'households']),\n",
    "    ('log', log_pipeline, ['total_bedrooms', 'total_rooms', 'population', 'households', 'median_income']), \n",
    "    ('geo', cluster_simil, ['latitude', 'longitude']), \n",
    "    ('cat', cat_pipeline, make_column_selector(dtype_include=object))\n",
    "],\n",
    "remainder=default_num_pipeline)\n",
    "\n",
    "\n",
    "housing_prepared = preprocessing.fit_transform(housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
